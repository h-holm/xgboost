Jupyter Notebooks presenting all steps taken in training a forest of gradient-boosted decision trees using XGBoost, ultimately achieving a somewhat-high-performing classifier. The dataset used is the IBM Sample Dataset for Telco Customer Churn. Steps taken and presented in the notebooks include pre-processing of data and handling of missing data, creation of an initial model and analysis of it, hyperparameter optimization and fitting of a final models, as well as investigating the final results using both confusion matrices and graphviz for plotting decision trees.
