{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "\n",
    "seed = 1337\n",
    "df = pd.read_csv('input/telco_customer_churn.csv')\n",
    "\n",
    "# Drop customerID, since it is not related to customer churn.\n",
    "df.drop(['customerID', ], axis=1, inplace=True) # axis=0 for rows, axis=1 for columns\n",
    "\n",
    "# Remove white space in columns for later plotting of tree.\n",
    "df.replace(' ', '_', regex=True, inplace=True)\n",
    "\n",
    "# Look into the dtype == object columns\n",
    "for col in df.select_dtypes(include='object'):\n",
    "    if len(col) < 7:\n",
    "        tabs = '\\t\\t\\t'\n",
    "    elif len(col) < 15:\n",
    "        tabs = '\\t\\t'\n",
    "    else:\n",
    "        tabs = '\\t'\n",
    "    # print(f'{col}:{tabs}{df[col].unique()}')\n",
    "\n",
    "df.loc[(df['TotalCharges'] == '_'), 'TotalCharges'] = 0.0\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'])\n",
    "\n",
    "# Let's convert all 'Yes'/'No' columns to 1/0 instead.\n",
    "cols = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']\n",
    "for col in cols:\n",
    "    df[col] = pd.Series(np.where(df[col].values == 'Yes', 1, 0), df.index)\n",
    "    df[col] = pd.to_numeric(df[col])\n",
    "\n",
    "# Convert Male / Female to 1 / 0 similar to above.\n",
    "df['gender'] = pd.Series(np.where(df['gender'].values == 'Male', 1, 0), df.index)\n",
    "df['gender'] = pd.to_numeric(df['gender'])\n",
    "\n",
    "# Divide the data into independent variables X and dependent variable y (Churn).\n",
    "X = df.drop('Churn', axis=1).copy()\n",
    "y = df['Churn'].copy()\n",
    "\n",
    "# Convert to one-hot encoding as this is suitable for trees.\n",
    "# We see that there are a couple of dtype == object columns that are not binary. These, we will one-hot encode.\n",
    "cols = ['MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaymentMethod']\n",
    "X_encoded = pd.get_dummies(X, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn percentage: 26.54%\n"
     ]
    }
   ],
   "source": [
    "# Check how many Churn == 1 samples there are compared to total.\n",
    "print(f'Churn percentage: {round((sum(y) / len(y) * 100), 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we only have 26.54% of Churn == 1 samples, we need to use stratification\n",
    "# when splitting out data into a training and a testing dataset. This way, we\n",
    "# ensure that the ratio of 1 / 0 will be the same in the training and test datasets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, random_state=seed, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn percentage train:\t26.54%\n",
      "Churn percentage test:\t26.52%\n"
     ]
    }
   ],
   "source": [
    "print(f'Churn percentage train:\\t{round((sum(y_train) / len(y_train) * 100), 2)}%')\n",
    "print(f'Churn percentage test:\\t{round((sum(y_test) / len(y_test) * 100), 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In sparse matrices, 0 is used for missing data. I explicitly state missing=None, even\n",
    "# though that is the default. But if our missing data points were '?', we would have said\n",
    "# missing='?'.\n",
    "clf_xgb = xgb.XGBClassifier(objective='binary:logistic', missing=None, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-aucpr:0.61852\n",
      "Will train until validation_0-aucpr hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-aucpr:0.63184\n",
      "[2]\tvalidation_0-aucpr:0.64216\n",
      "[3]\tvalidation_0-aucpr:0.64429\n",
      "[4]\tvalidation_0-aucpr:0.64326\n",
      "[5]\tvalidation_0-aucpr:0.64245\n",
      "[6]\tvalidation_0-aucpr:0.64733\n",
      "[7]\tvalidation_0-aucpr:0.64619\n",
      "[8]\tvalidation_0-aucpr:0.64595\n",
      "[9]\tvalidation_0-aucpr:0.64346\n",
      "[10]\tvalidation_0-aucpr:0.64230\n",
      "[11]\tvalidation_0-aucpr:0.64418\n",
      "[12]\tvalidation_0-aucpr:0.64327\n",
      "[13]\tvalidation_0-aucpr:0.64389\n",
      "[14]\tvalidation_0-aucpr:0.64245\n",
      "[15]\tvalidation_0-aucpr:0.64187\n",
      "[16]\tvalidation_0-aucpr:0.64169\n",
      "Stopping. Best iteration:\n",
      "[6]\tvalidation_0-aucpr:0.64733\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              random_state=1337, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=1337, subsample=1, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For creating our forest of XGBoosted trees, run fit(). Set early_stopping so we don't\n",
    "# need to wait if the model has stopped improving. Use Area under the PR Curve for evaluating.\n",
    "clf_xgb.fit(X_train,\n",
    "            y_train,\n",
    "            verbose=True,\n",
    "            early_stopping_rounds=10,\n",
    "            eval_metric='aucpr',\n",
    "            eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "plot_confusion_matrix requires matplotlib. You can install matplotlib with `pip install matplotlib`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/Github/xgboost/venv/lib/python3.8/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36mcheck_matplotlib_support\u001b[0;34m(caller_name)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1d13f4bf830b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Examine results.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m plot_confusion_matrix(clf_xgb,\n\u001b[0m\u001b[1;32m      6\u001b[0m                       \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                       \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/xgboost/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/xgboost/venv/lib/python3.8/site-packages/sklearn/metrics/_plot/confusion_matrix.py\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(estimator, X, y_true, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# doctest: +SKIP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \"\"\"\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mcheck_matplotlib_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"plot_confusion_matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/xgboost/venv/lib/python3.8/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36mcheck_matplotlib_support\u001b[0;34m(caller_name)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         raise ImportError(\n\u001b[0m\u001b[1;32m   1120\u001b[0m             \u001b[0;34m\"{} requires matplotlib. You can install matplotlib with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0;34m\"`pip install matplotlib`\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaller_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: plot_confusion_matrix requires matplotlib. You can install matplotlib with `pip install matplotlib`"
     ]
    }
   ],
   "source": [
    "# Our final forest actually only consists of 6 trees. Changing the early stopping argument\n",
    "# to a higher number does not result in improvements. Therefore, we accept the current model.\n",
    "\n",
    "# Examine results.\n",
    "plot_confusion_matrix(clf_xgb,\n",
    "                      X_test,\n",
    "                      y_test,\n",
    "                      values_format='d',\n",
    "                      display_labels=['Did not leave', 'Left'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
